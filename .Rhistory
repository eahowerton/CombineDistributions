agg$method <- "mean_trim"
agg$type <- trim_type
agg$n_trim <- keep_vals$n_trim
return(agg)
}
cdf_trim <- function(dat, n_trim, trim_type, avg_dir, ret_quantiles){
n_models <- length(unique(dat$model))
keep_vals <- keep_vals(trim_type, n_trim, n_models, avg_dir, "cdf")
if(length(keep_vals$keep) == 0){next}
#keep_ids <- mean_trim_ids(dat, keep_vals$keep)
if(avg_dir == "vincent"){
#browser()
d <- sapply(unique(dat$quantile),function(i){x <- dat %>% filter(quantile == i) %>% arrange(value);x <- x[keep_vals$keep,];return(list(x))})
d <- do.call(rbind, d)
agg <- calculate_aggregate_vin(d, ret_quantiles)
}
else if(avg_dir == "LOP"){
d <- dat
agg <- calculate_aggregate_LOP(d, keep_vals$keep, ret_quantiles) #unique(d$model),
}
agg$direction <- avg_dir
agg$method <- "cdf_trim"
agg$type <- trim_type
agg$n_trim <- keep_vals$n_trim
return(agg)
}
#### mean_trim() ####
test_that("Test mean_trim(): trim all but one, exterior",{
eps <- 0.001
quant <- seq(0,1,0.01)
n_trim <- 1
trim_type <- "exterior"
d <- expand.grid(min = 1:3,
quantile = quant)
d$model <- LETTERS[d$min]
d <- d %>% mutate(value = qunif(d$quantile, d$min, d$min+1)) %>% select(model, quantile, value)
# test output LOP
avg_dir <- "LOP"
test <- mean_trim(d, n_trim, trim_type, avg_dir, quant)
expect_equal(test$value, d[d$model == "B","value"])
# test output vincent
avg_dir <- "vincent"
test <- mean_trim(d, n_trim, trim_type, avg_dir)
expect_equal(test$value, d[d$model == "B","value"])
})
#### mean_trim() ####
test_that("Test mean_trim(): trim all but one, exterior",{
eps <- 0.001
quant <- seq(0,1,0.01)
n_trim <- 1
trim_type <- "exterior"
d <- expand.grid(min = 1:3,
quantile = quant)
d$model <- LETTERS[d$min]
d <- d %>% mutate(value = qunif(d$quantile, d$min, d$min+1)) %>% select(model, quantile, value)
# test output LOP
avg_dir <- "LOP"
test <- mean_trim(d, n_trim, trim_type, avg_dir, quant)
expect_equal(test$value, d[d$model == "B","value"])
# test output vincent
avg_dir <- "vincent"
test <- mean_trim(d, n_trim, trim_type, avg_dir, quant)
expect_equal(test$value, d[d$model == "B","value"])
})
test_that("Test mean_trim(): trim all but one, interior",{
eps <- 0.001
quant <- seq(0,1,0.01)
n_trim <- 1
trim_type <- "interior"
d <- expand.grid(model = LETTERS[1:3],
quantile = quant)
d <- d %>% mutate(value = qunif(d$quantile))
# test output LOP
avg_dir <- "LOP"
test <- mean_trim(d, n_trim, trim_type, avg_dir, quant)
expect_equal(test$value, d[d$model == "B" & round((d$quantile*100)%%5) ==0,"value"])
# test output vincent
avg_dir <- "vincent"
test <- mean_trim(d, n_trim, trim_type, avg_dir, quant)
expect_equal(test$value, d[d$model == "B","value"])
})
test_that("Test mean_trim(): trim all but one, interior",{
eps <- 0.001
quant <- seq(0,1,0.01)
n_trim <- 1
trim_type <- "interior"
d <- expand.grid(model = LETTERS[1:3],
quantile = quant)
d <- d %>% mutate(value = qunif(d$quantile))
# test output LOP
avg_dir <- "LOP"
test <- mean_trim(d, n_trim, trim_type, avg_dir, quant)
expect_equal(test$value, d[d$model == "B","value"])
# test output vincent
avg_dir <- "vincent"
test <- mean_trim(d, n_trim, trim_type, avg_dir, quant)
expect_equal(test$value, d[d$model == "B","value"])
})
#### cdf_trim() ####
test_that("Test cdf_trim()",{
eps <- 0.001
quant <- seq(0,1,0.01)
n_trim <- 1
trim_type <- "exterior"
d <- expand.grid(min = 1:3,
quantile = quant)
d$model = LETTERS[d$min]
d$max = ifelse(d$model == "B", 3, 4)
d <- d %>% mutate(value = qunif(d$quantile, d$min, d$max)) %>% select(model, quantile, value)
# test output LOP
avg_dir <- "LOP"
test <- cdf_trim(d, n_trim, trim_type, avg_dir, quant)
expect_true(all(test$value - c(seq(2,2.5, 0.01), seq(2.65, 4, 0.03))<eps))
# test output vincent
avg_dir <- "vincent"
test <- cdf_trim(d, n_trim, trim_type, avg_dir, quant)
expect_true(all(test$value - c(seq(2,2.5, 0.01), seq(2.53, 4, 0.03))<eps))
})
ps <- 0.001
quant <- seq(0,1,0.01)
n_trim <- 1
trim_type <- "exterior"
d <- expand.grid(min = 1:3,
quantile = quant)
d$model = LETTERS[d$min]
d$max = ifelse(d$model == "B", 3, 4)
d <- d %>% mutate(value = qunif(d$quantile, d$min, d$max)) %>% select(model, quantile, value)
vg_dir <- "LOP"
test <- cdf_trim(d, n_trim, trim_type, avg_dir, quant)
head(test$value)
#### cdf_trim() ####
test_that("Test cdf_trim()",{
eps <- 0.001
quant <- seq(0,1,0.01)
n_trim <- 1
trim_type <- "exterior"
d <- expand.grid(min = 1:3,
quantile = quant)
d$model = LETTERS[d$min]
d$max = ifelse(d$model == "B", 3, 4)
d <- d %>% mutate(value = qunif(d$quantile, d$min, d$max)) %>% select(model, quantile, value)
# test output LOP
avg_dir <- "LOP"
test <- cdf_trim(d, n_trim, trim_type, avg_dir, quant)
expect_true(all(test$value - c(seq(2,2.5, 0.01), seq(2.53, 4, 0.03))<eps))
# test output vincent
avg_dir <- "vincent"
test <- cdf_trim(d, n_trim, trim_type, avg_dir, quant)
expect_true(all(test$value - c(seq(2,2.5, 0.01), seq(2.53, 4, 0.03))<eps))
})
test_file("src/aggregation_methods/test_Trimming.R")
test_file("src/aggregation_methods/test_Trimming.R")
test_file("src/aggregation_methods/test_LOP.R")
test_file("src/aggregation_methods/test_vincent.R")
setwd("~/Documents/GitHub/covid19-scenario-hub_visualization")
#### PREAMBLE -----------------------
library(reshape2)
library(ggplot2)
library(dplyr)
library(readr)
library(gridExtra)
library(scales)
library(stringr)
library(cowplot)
require(RcppRoll)
#### INPUT DATA -----------------------
#### individual models ####
f <- c(#"data-processed/Ensemble/2021-03-27-Ensemble_point.csv",
"data-processed/JHU_IDD-CovidSP/2021-03-28-JHU_IDD-CovidSP.csv",
"data-processed/JHUAPL-Bucky/2021-03-29-JHUAPL-Bucky.csv",
"data-processed/Karlen-pypm/2021-03-28-Karlen-pypm.csv",
"data-processed/MOBS_NEU-GLEAM_COVID/2021-03-28-MOBS_NEU-GLEAM_COVID.csv",
"data-processed/USC-SIkJalpha/2021-03-27-USC-SIkJalpha.csv",
"data-processed/UVA-adaptive/2021-03-27-UVA-adaptive.csv")
m <- c("JHU_IDD-CovidSP", "JHUAPL-Bucky", "Karlen-pypm", #"Ensemble",
"MOBS_NEU-GLEAM_COVID", "USC-SIkJalpha", "UVA-adaptive")
full_df <- list()
for(i in 1:length(f)){
df <- read_csv(file.path(f[i]))
df$model <- m[i]
full_df[[i]] <- df %>% filter(quantile %in% c(0.25, 0.5, 0.75), str_detect(target, "inc"))
}
full_df<- bind_rows(full_df)
# manually calculate median for ensemble
ens <- full_df %>%
group_by(scenario_name, location, target, target_end_date, quantile) %>%
summarise(value = median(value)) %>%
mutate(model = "Ensemble")
full_df <- rbind(full_df %>% select(scenario_name, location, target, target_end_date, quantile, value, model),
ens)
# indices for each target type
case_index <- grep("case", full_df$target)
death_index <- grep("death", full_df$target)
hosp_index <- grep("hosp", full_df$target)
# create target_type column for faceting of plots
full_df$target_type <- NA
full_df$target_type[case_index] <- "Reported Cases"
full_df$target_type[death_index] <- "Deaths"
full_df$target_type[hosp_index] <- "Hospitalizations"
lab_team <- data.frame(model = full_df %>%
filter(model != "Ensemble") %>%
pull(model) %>%
unique() %>%
sort())
lab_team$label = LETTERS[1:nrow(lab_team)]
full_df <- left_join(full_df, lab_team)
View(ens)
unqiue(ens$target_end_date)
unique(ens$target_end_date)
ens %>% filter(location == "US", target_end_date == "2021-07-31")
ens %>% filter(location == "US", target_end_date == "2021-07-31",
quantile == 0.5)
ens %>% filter(location == "US", target_end_date == "2021-07-31",
quantile == 0.5, str_detect("inc", target))
colnames(ens)
ens %>% filter(location == "US", target_end_date == "2021-07-31",
quantile == 0.5, str_detect(target, "inc"))
View(ens %>% filter(location == "US", target_end_date == "2021-07-31",
quantile == 0.5, str_detect(target, "inc")))
View(ens %>% filter(location == "US", target_end_date == "2021-07-31",
quantile == 0.5, str_detect(target, "inc"), scenario_name %in% c("lowVac_lowNPI", "highVac_highNPI")),
)
View(ens %>% filter(location == "US", target_end_date == "2021-07-31",
quantile == 0.5, str_detect(target, "inc"), scenario_name %in% c("lowVac_lowNPI", "highVac_modNPI")),
)
unique(ens$target_end_date)
View(ens %>% filter(location == "US", target_end_date %in% c("2021-07-31","2021-09-25" ),
quantile == 0.5, str_detect(target, "inc"), scenario_name %in% c("lowVac_lowNPI", "highVac_modNPI")),
)
ens %>% filter(location == "US",
target_end_date %in% c("2021-07-31","2021-09-25"),
quantile == 0.5, str_detect(target, "inc"),
scenario_name %in% c("lowVac_lowNPI", "highVac_modNPI"))
unqiue(ens$target)
unique(ens$target)
unique(ens$target_end_date)
ens %>% filter(location == "US",
target_end_date %in% c("2021-07-31","2021-09-25")
)
ens %>% filter(target_end_date == "2021-09-25")
ens %>% filter(target_end_date == "2021-09-25", location == "US")
out <- ens %>% filter(location == "US",
target_end_date %in% c("2021-07-31"),
quantile == 0.5, str_detect(target, "inc"),
scenario_name %in% c("lowVac_lowNPI", "highVac_modNPI"))
out2 <- ens %>% filter(location == "US",
target_end_date %in% c("2021-09-25"),
quantile == 0.5, str_detect(target, "inc"),
scenario_name %in% c("lowVac_lowNPI", "highVac_modNPI"))
out3 <- rbind(out, out2)
View(out3)
out <- ens %>% filter(location == "US",
target_end_date %in% c("2021-07-31"),
quantile == 0.5, str_detect(target, "inc"),
scenario_name %in% c("lowVac_lowNPI", "highVac_modNPI"))
out2 <- ens %>% filter(location == "US",
target_end_date == "2021-09-25",
quantile == 0.5, str_detect(target, "inc"),
scenario_name %in% c("lowVac_lowNPI", "highVac_modNPI"))
out <- ens %>% filter(location == "US",
target_end_date == "2021-07-31",
quantile == 0.5, str_detect(target, "inc"),
scenario_name %in% c("lowVac_lowNPI", "highVac_modNPI"))
out2 <- ens %>% filter(location == "US",
target_end_date == "2021-09-25",
quantile == 0.5, str_detect(target, "inc"),
scenario_name %in% c("lowVac_lowNPI", "highVac_modNPI"))
out3 <- rbind(out, out2)
View(out3)
write.csv(out, "MikeJVals.csv")
write.csv(out3, "MikeJVals.csv")
head(ens)
# worst case
# indices for each target type
case_index <- grep("case", ens$target)
death_index <- grep("death", ens$target)
hosp_index <- grep("hosp", ens$target)
# create target_type column for faceting of plots
ens$target_type <- NA
ens$target_type[case_index] <- "Reported Cases"
ens$target_type[death_index] <- "Deaths"
ens$target_type[hosp_index] <- "Hospitalizations"
w <- ens %>%
filter(location == "US", quantile == 0.5) %>%
group_by(target_type) %>%
mutate(flg = ifelse(value == max(value), 1,0))
View(w)
write.csv(w %>% filter(flg == 1), "MikeJVals_worst.csv")
View(ens)
write.csv(out3 %>% mutate(value = round(value, 1)), "MikeJVals.csv")
write.csv(w %>% filter(flg == 1) %>% mutate(value = round(value, 1)), "MikeJVals_worst.csv")
View(ens)
# indices for each target type
case_index <- grep("case", full_df$target)
death_index <- grep("death", full_df$target)
hosp_index <- grep("hosp", full_df$target)
full_df <- rbind(full_df %>% select(scenario_name, location, target, target_end_date, quantile, value, model),
ens)
# create target_type column for faceting of plots
full_df$target_type <- NA
full_df$target_type[case_index] <- "Reported Cases"
full_df$target_type[death_index] <- "Deaths"
full_df$target_type[hosp_index] <- "Hospitalizations"
lab_team <- data.frame(model = full_df %>%
filter(model != "Ensemble") %>%
pull(model) %>%
unique() %>%
sort())
lab_team$label = LETTERS[1:nrow(lab_team)]
full_df <- left_join(full_df, lab_team)
# cast to include median and interval
df_cast <- dcast(full_df,
scenario_name + location + target_type + target_end_date + model + label ~ quantile, value.var = "value")
colnames(df_cast)[7:9] = c("lower", "median", "upper")
#### ground truth ####
loc <- read.csv("./data-locations/locations.csv",stringsAsFactors = T)
hosp_file_name <- "COVID-19_Reported_Patient_Impact_and_Hospital_Capacity_by_State_Timeseries"
# incident deaths
id  <- read.csv("code/report generation/report_data/truth-Incident Deaths.csv", colClasses = c("date" = "Date"),stringsAsFactors = T)
id <- id %>%
dplyr::group_by(location) %>%
dplyr::mutate(weekly_sum = roll_sum(value, n = 7, fill = NA, align = "right")) %>%
dplyr::ungroup()
# incident cases
ic <- read.csv("code/report generation/report_data/truth-Incident Cases.csv", colClasses = c("date" = "Date"))
ic <- ic %>%
dplyr::group_by(location) %>%
dplyr::mutate(weekly_sum = roll_sum(value, n = 7, fill = NA, align = "right")) %>%
dplyr::ungroup()
# incident hospitalizations
ih <- read.csv(paste0("code/report generation/report_data/",hosp_file_name,".csv"), colClasses = c("date" = "Date"), fileEncoding="UTF-8-BOM")
ih <- ih %>%
#dplyr::rename("state" = "Ã¯..state") %>%
dplyr::mutate(value = previous_day_admission_adult_covid_confirmed + previous_day_admission_pediatric_covid_confirmed) %>%
dplyr::mutate(date = date - 1) %>% # account for fact that admissions are for previous day
dplyr::select(date, state, value)
# Sum across states to get total US incident hospitalizations
us_ih <- ih %>%
dplyr::group_by(date) %>%
dplyr::summarize(value = sum(value, na.rm = TRUE)) %>%
dplyr::mutate(state = "US")
ih <- ih %>%
dplyr::bind_rows(us_ih) %>%
dplyr::group_by(state) %>%
dplyr::mutate(weekly_sum = roll_sum(value, n = 7, fill = NA, align = "right")) %>%
dplyr::ungroup()
last_date <- as.Date("2021-04-30")
dates <- seq(from = as.Date("2020-01-04"), to = last_date, by = 7)
deaths <- id %>%
dplyr::filter(date %in% dates, location %in% loc$location) %>%
dplyr::select(date, location, location_name, weekly_sum) %>%
dplyr::rename("value" = "weekly_sum") %>%
dplyr::mutate(target_type = "Deaths")
cases <- ic %>%
dplyr::filter(date %in% dates, location %in% loc$location) %>%
dplyr::select(date, location, location_name, weekly_sum) %>%
dplyr::rename("value" = "weekly_sum") %>%
dplyr::mutate(target_type = "Reported Cases")
hosp <- ih %>%
dplyr::filter(date %in% dates, state %in% loc$abbreviation) %>%
dplyr::select(date, state, weekly_sum) %>%
dplyr::rename(value = weekly_sum) %>%
dplyr::filter(date >= "2020-09-19") %>% # early hospitalization data not reliable
dplyr::rename(abbreviation = state) %>%
dplyr::left_join(dplyr::select(loc, abbreviation, location, location_name)) %>%
dplyr::select(-abbreviation) %>%
dplyr::mutate(target_type = "Hospitalizations")
truth <- dplyr::bind_rows(deaths, cases, hosp)
rm(ih, id, ic, deaths, cases, hosp)
start.date = as.Date("2020-10-01")
#### setup ####
projection.start.date <- as.Date("2021-03-27")
v_line_lab_shift = 20
breaks <- seq(as.Date("2020-10-01"), as.Date("2021-09-08"), "month") #as.Date("2021-07-01")
labs_scenario <- c("High vaccination, Moderate NPI compliance",
"High vaccination, Low NPI compliance",
"Low vaccination, Moderate NPI compliance",
"Low vaccination, Low NPI compliance")
names(labs_scenario) <- c("highVac_modNPI", "highVac_lowNPI", "lowVac_modNPI", "lowVac_lowNPI")
# order factors
full_df$scenario_name = factor(full_df$scenario_name, levels = c("highVac_modNPI",
"highVac_lowNPI",
"lowVac_modNPI",
"lowVac_lowNPI"))
labs_target <- c("Reported Cases", "Hospitalizations", "Deaths")
names(labs_target) <- c("26 wk ahead cum case", "26 wk ahead cum hosp", "26 wk ahead cum death")
full_df$target = factor(full_df$target_type, levels = c("Reported Cases",
"Hospitalizations",
"Deaths"))
colors <- c("#1F1F1F", "#BDBEBE", "#00008B", "#1E90FF")
names(colors) <- c("lowVac_lowNPI",
"lowVac_modNPI",
"highVac_lowNPI",
"highVac_modNPI")
ggplot(data = full_df %>% filter(model == "Ensemble", location == "US", target == "Reported Cases"))+
geom_line(aes(x = target_end_date, y = value, color = scenario_name))
head(full_df)
ggplot(data = full_df %>% filter(model == "Ensemble", location == "US", target == "Reported Cases", quantile == 0.5))+
geom_line(aes(x = target_end_date, y = value, color = scenario_name))
ggplot(data = full_df %>% filter(model == "Ensemble", location == "US", target == "Reported Cases", quantile == 0.5),
aes(x = target_end_date, y = value, color = scenario_name))+
geom_line()+
geom_text(data = full_df %>% filter(model == "Ensemble", location == "US", target == "Reported Cases", quantile == 0.5, value == max(value)))
ggplot(data = full_df %>% filter(model == "Ensemble", location == "US", target == "Reported Cases", quantile == 0.5),
aes(x = target_end_date, y = value, color = scenario_name))+
geom_line()+
geom_text(data = full_df %>% filter(model == "Ensemble", location == "US", target == "Reported Cases", quantile == 0.5, value == max(value)),
aes(label = round(value)))
full_df %>% filter(model == "Ensemble", location == "US", target == "Reported Cases", quantile == 0.5, value == max(value))
full_df <- full_df %>%
filter(location == "US", quantile == 0.5, model == "Ensemble") %>%
group_by(target_type) %>%
mutate(flg = ifelse(value == max(value), 1,0))
ggplot(data = full_df %>% filter(model == "Ensemble", location == "US", target == "Reported Cases", quantile == 0.5),
aes(x = target_end_date, y = value, color = scenario_name))+
geom_line()+
geom_text(data = full_df %>% filter(model == "Ensemble", location == "US", target == "Reported Cases", quantile == 0.5, flg == 1),
aes(label = round(value)))
w <- ens %>%
filter(location == "US", quantile == 0.5) %>%
group_by(target_type, scenario_name) %>%
mutate(flg = ifelse(value == max(value), 1,0))
View(w)
isntall.packages("roxygen")
install.packages("roxygen2")
devtools::document()
install.packages("devtools")
devtools::document()
setwd("~/Documents/GitHub/CombineDistributions")
devtools::document()
roxygenize()
library(roxygen2)
roxygenize()
roxygenize()
roxygenize(vincent.R)
roxygenize("vincent.R")
roxygenize("~vincent.R")
prompt(calculate_aggregate_vin)
#' Implement quantile averaging
#'
#' Given a set of cumulative distribution functions  (assume for now: defined on same values),
#'   combine using quantile averaging (also called Vincent average).
#'   This method calculates the (weighted) average of values at a given quantile
#'
#' @param dat data.frame containing cdfs to be combined. See details for structure.
#' @param ret_quantiles A matrix with length(x) rows, and n columns where n is the number of distrbutions to combine
#' @return vin A data.frame with \code{quantile} and \code{value} of quantile averaged aggregate.
#'
#' @details \code{dat} should contain three columns, named \code{id}, \code{quantile}, and \code{value}.
#' \code{id} contains identifiers to distinguish between different individual cdfs.
#' \code{quantile} contains quantiles (between 0 and 1) and \code{value} contains the cdf value for that model and quantile.
#'
#' @example
#' dat <- expand.grid(id = c("A", "B"),
#'                    quantile = seq(0,1,0.01))
#' dat$value <- ifelse(dat$id == "A", qnorm(dat$quantile), qnorm(dat$quantile, 0,2))
#' calculate_aggregate_vin(dat, seq(0,1,0.05))
calculate_aggregate_vin <- function(dat, ret_quantiles){ #model_weights
#dat <- left_join(dat, model_weights)
# calcualte vincent average
vinc <- dat %>%
tidyverse::group_by(quantile) %>%
tidyverse::summarise(value= mean(value))
# return specified quantiles
if(all(round(ret_quantiles,4) %in% round(unique(vinc$quantile),4))){ # rounding probably not the best way to handle
return(vinc %>% tidyverse::filter(round(quantile,4) %in% round(ret_quantiles,4)))
}
else{
warning("more quantiles to return than provided, interpolating missing quantiles")
vinc_interp <- approx(vinc$quantile, vinc$value, xout = ret_quantiles)
vinc <- tibble(quantile = vinc_interp$x,
value = vinc_interp$y)
return(vinc)
}
}
prompt(calculate_aggregate_vin)
usethis::use_testthat()
devtools::test()
load_all()
library(devtools)
load_all()
library(devtools)
has_devel  ()
use_pipe()
document()
source('~/Documents/GitHub/CombineDistributions/R/implement_aggregation.R')
document()
rm(list = c("calculate_aggregate_vin"))
load_all
document()
document
document()
previewRd("calculate_aggregate_vin.Rd")
library(rstudioapi)
previewRd("calculate_aggregate_vin.Rd")
previewRD("calculate_aggregate_vin.Rd")
preview("calculate_aggregate_vin.Rd")
document()
devtools::load_all(".")
?calculate_aggregate_vin()
?calculate_aggregate_vin()
source('~/Documents/GitHub/CombineDistributions/R/LOP.R', echo=TRUE)
?create_interp_fns
document()
?calculate_aggregate_LOP
?create_interp_fns
?evaluate_cdf
?trim_cdf
?avg_probs
?avg_probs
?mean_trim
library(CombineDistributions)
